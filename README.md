> *No healthy human being would ever mistake a turtle for a rifle or parking sign for a refrigerator.* Gary Marcus, Deep Learning: A Critical Appraisal

A curated list of recent papers exploring the qualitative limits of deep learning tools for NLP and the open-fields beyond them. I limit this selection to constructive papers with interesting insights.

Outside of focus: interpretability, better models of long-term dependencies (memory)

# Models
- [Evaluating Compositionality in Sentence Embeddings](http://arxiv.org/abs/1802.04302) by Dasgupta, I., Guo, D., Stuhlmüller, A., Gershman, S. J., & Goodman, N. D. (2018).
- [Adversarial Examples for Evaluating Reading Comprehension Systems](http://arxiv.org/abs/1707.07328) by Jia, R., & Liang, P. (2017)
- [Generalization without systematicity: On the compositional skills of sequence-to-sequence recurrent networks](https://arxiv.org/abs/1711.00350) by Lake, B. M., & Baroni, M. (2017)
- [Tree-structured composition in neural networks without tree-structured architectures](http://arxiv.org/abs/1506.04834) by Bowman, S. R., Manning, C. D., & Potts, C. (2015)
- Not NLP: [Schema Networks: Zero-shot Transfer with a Generative Causal Model of Intuitive Physics](http://arxiv.org/abs/1706.04317) by Kansky, K., Silver, T., Mély, D. A., Eldawy, M., Lázaro-Gredilla, M., Lou, X., … George, D. (2017)

# NLP Datasets
- [Annotation Artifacts in Natural Language Inference Data](http://arxiv.org/abs/1803.02324) by Gururangan, S., Swayamdipta, S., Levy, O., Schwartz, R., Bowman, S. R., & Smith, N. A. (2018)
- [Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge](http://arxiv.org/abs/1803.05457) by Clark, P., Cowhey, I., Etzioni, O., Khot, T., Sabharwal, A., Schoenick, C., & Tafjord, O. (2018)

# Opinions/review articles
- [Pre-Proceedings of the Cognitive Computation Symposium: Thinking Beyond Deep Learning](http://daselab.cs.wright.edu/nesy/CoCoSym2018/index.html) (CoCoSym 2018) by Besold, T. R. (n.d.).
- [Building Machines That Learn and Think Like People](http://arxiv.org/abs/1604.00289) by Lake, B. M., Ullman, T. D., Tenenbaum, J. B., & Gershman, S. J. (2016).
- DeepMind's response to the previous Lake et al. article [Building Machines that Learn and Think for Themselves: Commentary on Lake et al., Behavioral and Brain Sciences](http://arxiv.org/abs/1711.08378) by Botvinick, M., Barrett, D. G. T., Battaglia, P., de Freitas, N., Kumaran, D., Leibo, J. Z., … Hassabis, D. (2017)
- Gary Marcus Critical Appraisal trilogy: [Deep Learning: A Critical Appraisal](https://arxiv.org/abs/1801.00631), [Innateness, AlphaZero, and Artificial Intelligence](https://arxiv.org/abs/1801.05667) and [In defense of skepticism about deep learning](https://medium.com/@GaryMarcus/in-defense-of-skepticism-about-deep-learning-6e8bfd5ae0f1)
- UC Berkeley:
  - [A Berkeley View of Systems Challenges for AI](http://arxiv.org/abs/1712.05855) by Stoica, I., Song, D., Popa, R. A., Patterson, D., Mahoney, M. W., Katz, R., … Abbeel, P. (2017)
  - Researches at UB Berkeley's [Center for Human-Compatible AI](http://humancompatible.ai/publications)

# Debats / less formal
- Joel Grus' [Fizz Buzz joke](http://joelgrus.com/2016/05/23/fizz-buzz-in-tensorflow/)
- Yann LeCun and Christopher Manning on February 2 2018, at Stanford University [What innate priors should we build into the architecture of deep learning systems?](https://www.youtube.com/watch?v=fKk9KhGRBdI)
- Yann LeCun and Gary Marcus at NYU, October 5 2017 [Does AI Need More Innate Machinery?](https://www.youtube.com/watch?v=vdWPQ6iAkT4)
